{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from pickle ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data from pickle ...\")\n",
    "import pickle\n",
    "with open(\"_vocab.pickle\", 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "with open(\"_image_train.pickle\", 'rb') as f:\n",
    "    _, images_train = pickle.load(f)\n",
    "with open(\"_image_test.pickle\", 'rb') as f:\n",
    "    _, images_test = pickle.load(f)\n",
    "with open(\"_n.pickle\", 'rb') as f:\n",
    "    n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test = pickle.load(f)\n",
    "with open(\"_caption.pickle\", 'rb') as f:\n",
    "    captions_ids_train, captions_ids_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of image in training: ', 8000)\n",
      "('Number of image in testing: ', 189)\n",
      "('Number of caption in training: ', 80000)\n",
      "('Number of caption in testing: ', 1890)\n"
     ]
    }
   ],
   "source": [
    "# summarize the input data\n",
    "print(\"Number of image in training: \", len(images_train))\n",
    "print(\"Number of image in testing: \", len(images_test))\n",
    "print(\"Number of caption in training: \", len(captions_ids_train))\n",
    "print(\"Number of caption in testing: \", len(captions_ids_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 7, 4, 12, 8, 36, 16, 9, 37, 34, 16, 81, 99, 13, 21, 2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_ids_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorlayer.nlp.Vocabulary at 0x7f879c2a12d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'skipthoughts' from './skip-thoughts'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.load_source(\"skipthoughts\", \"./skip-thoughts\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import theano\n",
    "import theano.tensor as tensor\n",
    "\n",
    "import cPickle as pkl\n",
    "import numpy\n",
    "import copy\n",
    "import nltk\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from scipy.linalg import norm\n",
    "from nltk.tokenize import word_tokenize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
